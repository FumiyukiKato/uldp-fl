{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path_project = os.path.dirname(os.path.abspath('.'))\n",
    "import sys\n",
    "sys.path.append(os.path.join(path_project, 'src'))\n",
    "sys.path.append(os.path.join(path_project, 'exp/script'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "import subprocess\n",
    "import re\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "import results_saver\n",
    "import options\n",
    "\n",
    "from secure_simulator import SecureWeightingFLSimulator\n",
    "from simulator import FLSimulator\n",
    "from mylogger import logger_set_debug\n",
    "\n",
    "img_path = os.path.join(path_project, 'exp', 'img')\n",
    "results_path = os.path.join(path_project, 'exp', 'results')\n",
    "default_args = options.build_default_args(path_project)\n",
    "\n",
    "PLOT_MARKERS = ['o', 'v', 's', 'X', 'p', '*', 'h', '^', '<', '>', 'H', 'D', 'd', 'P']\n",
    "METHOD_ORDER = [\"DEFAULT\", \"ULDP-NAIVE\", \"ULDP-GROUP-2\", \"ULDP-GROUP-8\", \"ULDP-SGD\", \"ULDP-AVG\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook show the calculation of private weighting method. And evaluate the overhead of the private method with artiricial dataset and model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phe import paillier\n",
    "from secure_aggregation import (\n",
    "    SecureAggregator,\n",
    "    SecureLocalTrainer,\n",
    "    PRIMARY_SILO_ID,\n",
    "    gen_random_int_in_GFp,\n",
    "    non_recursive_mod_inverse,\n",
    "    integerize,\n",
    "    encode,\n",
    "    decode,\n",
    "    re_integerize,\n",
    "    PRECISION,\n",
    "    DIVISIBLE_NUM,\n",
    "    get_perfect_divisible_number,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_LCM digit:  867\n"
     ]
    }
   ],
   "source": [
    "DIVISIBLE_NUM = get_perfect_divisible_number(2000)\n",
    "print(\"C_LCM digit: \", len(str(DIVISIBLE_NUM)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n digit:  925\n",
      "[12345678.9 -12345678.9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Private weighting calculation example\n",
    "\n",
    "pk, sk = paillier.generate_paillier_keypair(n_length=3072)\n",
    "print(\"n digit: \", len(str(pk.n)))\n",
    "modulus = pk.n\n",
    "pk.max_int = modulus - 1\n",
    "r = gen_random_int_in_GFp(pk.max_int, np.random.RandomState())\n",
    "N = 900\n",
    "n = 90\n",
    "w = 0.01234567890123456789\n",
    "w_list = np.array([w, -w]).astype(object)\n",
    "\n",
    "int_w_list = integerize(w_list, PRECISION)\n",
    "\n",
    "int_w_list = encode(int_w_list, modulus)\n",
    "\n",
    "inv_DIVISIBLE_NUM = non_recursive_mod_inverse(DIVISIBLE_NUM, modulus)\n",
    "\n",
    "a = non_recursive_mod_inverse(N * r, modulus)\n",
    "\n",
    "enc_a = pk.encrypt(a)\n",
    "enc_coef = enc_a  * n * r * DIVISIBLE_NUM\n",
    "enc_out = int_w_list * enc_coef\n",
    "\n",
    "out = (\n",
    "    np.vectorize(lambda x: decode(sk.decrypt(x), modulus))(enc_out)\n",
    "    / DIVISIBLE_NUM\n",
    ")\n",
    "print(out)\n",
    "(\n",
    "    np.abs(\n",
    "        re_integerize(out, PRECISION)\n",
    "        - np.array([0.001234567890123456789, -0.001234567890123456789])\n",
    "    ).max()\n",
    "    < 1e-7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_artificail_model(input_size, output_size, num_layers, nodes_per_layer):\n",
    "    layers = []\n",
    "    layers.append(nn.Linear(input_size, nodes_per_layer))\n",
    "    layers.append(nn.ReLU())\n",
    "    \n",
    "    for _ in range(num_layers-1):\n",
    "        layers.append(nn.Linear(nodes_per_layer, nodes_per_layer))\n",
    "        layers.append(nn.ReLU())\n",
    "    \n",
    "    layers.append(nn.Linear(nodes_per_layer, output_size))\n",
    "    \n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def prepare_artificial_dataset(n_users, n_silos, n_samples, n_features, n_classes, random_state):\n",
    "    local_dataset_per_silos = {}\n",
    "    for silo_id in range(n_silos):\n",
    "        X, y = make_classification(n_samples=n_samples, n_features=n_features, n_classes=n_classes, random_state=random_state.randint(2**20))\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "        train_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "        users = list(range(n_users))\n",
    "        selected_users = random_state.choice(users, size=n_samples, replace=True)\n",
    "        user_hist = {}\n",
    "        for user_id in selected_users:\n",
    "            if user_id not in user_hist:\n",
    "                user_hist[user_id] = 0\n",
    "            user_hist[user_id] += 1\n",
    "        local_dataset_per_silos[silo_id] = (train_dataset, [], user_hist, selected_users)\n",
    "\n",
    "    X_test, y_test = make_classification(n_samples=100, n_features=n_features, n_classes=n_classes, random_state=random_state.randint(2**20))\n",
    "    X_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "    all_test_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "    return [], all_test_dataset, local_dataset_per_silos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_secure_simulation(seed, n_users, n_silos, n_samples, n_features, n_classes, n_layers, nodes_per_layer):\n",
    "    device = \"cpu\"\n",
    "    data_seed = seed\n",
    "    data_random_state = np.random.RandomState(seed=data_seed)\n",
    "\n",
    "    # load data\n",
    "    train_dataset, test_dataset, local_dataset_per_silos = prepare_artificial_dataset(\n",
    "        n_users=n_users,\n",
    "        n_silos=n_silos,\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        n_classes=n_classes,\n",
    "        random_state=data_random_state,\n",
    "    )\n",
    "\n",
    "    # load model\n",
    "    model = create_artificail_model(input_size=n_features, output_size=n_classes, num_layers=n_layers, nodes_per_layer=nodes_per_layer)\n",
    "    param_size = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    print(\"parameter_size\", param_size)\n",
    "    print(\"n_users\", n_users)\n",
    "    print(\"n_silos\", n_silos)\n",
    "    print(\"n_samples\", n_samples)\n",
    "\n",
    "\n",
    "    # start training\n",
    "    base_seed = np.random.RandomState(seed=seed).randint(2**32 - 1)\n",
    "\n",
    "    simulator = SecureWeightingFLSimulator(\n",
    "        seed=base_seed,\n",
    "        model=model,\n",
    "        train_dataset=train_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        local_dataset_per_silos=local_dataset_per_silos,\n",
    "        n_silos=n_silos,\n",
    "        n_users=n_users,\n",
    "        device=device,\n",
    "        n_total_round=1,\n",
    "        n_silo_per_round=n_silos,\n",
    "        local_learning_rate=0.01,\n",
    "        global_learning_rate=0.1,\n",
    "        local_batch_size=8,\n",
    "        weight_decay=0.01,\n",
    "        client_optimizer=\"sgd\",\n",
    "        local_epochs=10,\n",
    "        agg_strategy=\"ULDP-AVG-w\",\n",
    "        clipping_bound=1.0,\n",
    "        sigma=5.0,\n",
    "        delta=1e-5,\n",
    "        group_k=2,\n",
    "        dataset_name=\"artificial\",\n",
    "        sampling_rate_q=0.3,\n",
    "    )\n",
    "    simulator.run()\n",
    "    results = simulator.get_results()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "n_users = 10\n",
    "n_silos = 3\n",
    "n_samples = 10000\n",
    "\n",
    "n_features = 4\n",
    "n_classes = 2\n",
    "\n",
    "n_layers = 0\n",
    "nodes_per_layer = 2\n",
    "\n",
    "# run_secure_simulation(seed, n_users, n_silos, n_samples, n_features, n_classes, n_layers, nodes_per_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter_size 16\n",
      "n_users 10\n",
      "n_silos 3\n",
      "n_samples 100\n",
      "[16:11:34 INFO] Start federated learning simulation with secure weighting.\n",
      "key_exchange 1.051577091217041\n",
      "multiplicative_blind_user_hist 4.12992000579834\n",
      "training_silo_0 85.44185900688171\n",
      "training_silo_1 84.4896731376648\n",
      "training_silo_2 89.13435697555542\n",
      "[16:16:00 INFO] Privacy spent: epsilon = 0.794522032537103 (round 0)\n",
      "aggregation 2.1517958641052246\n",
      "[16:16:00 INFO] |----- Global test result of round 0\n",
      "[16:16:00 INFO] \t |----- Test/Acc: 0.66 (100), Test/Loss: 0.6677354574203491\n",
      "global_test 0.002007007598876953\n",
      "total 1.2874603271484375e-05\n",
      "[16:16:00 INFO] Finish federated learning simulation\n",
      "parameter_size 16\n",
      "n_users 10\n",
      "n_silos 3\n",
      "n_samples 1000\n",
      "[16:16:06 INFO] Start federated learning simulation with secure weighting.\n",
      "key_exchange 1.0447149276733398\n",
      "multiplicative_blind_user_hist 4.114915132522583\n",
      "training_silo_0 86.59528112411499\n",
      "training_silo_1 83.68200397491455\n",
      "training_silo_2 86.97076797485352\n",
      "[16:20:31 INFO] Privacy spent: epsilon = 0.794522032537103 (round 0)\n",
      "aggregation 2.145372152328491\n",
      "[16:20:31 INFO] |----- Global test result of round 0\n",
      "[16:20:31 INFO] \t |----- Test/Acc: 0.51 (100), Test/Loss: 0.7244009375572205\n",
      "global_test 0.001657724380493164\n",
      "total 1.4066696166992188e-05\n",
      "[16:20:31 INFO] Finish federated learning simulation\n"
     ]
    }
   ],
   "source": [
    "for _n_samples in [100, 1000]:\n",
    "    run_secure_simulation(seed, n_users, n_silos, _n_samples, n_features, n_classes, n_layers, nodes_per_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter_size 107\n",
      "n_users 10\n",
      "n_silos 3\n",
      "n_samples 10000\n",
      "[17:08:02 INFO] Start federated learning simulation with secure weighting.\n",
      "key_exchange 1.0656218528747559\n",
      "multiplicative_blind_user_hist 4.129354000091553\n",
      "training_silo_0 287.4782841205597\n",
      "training_silo_1 303.5857400894165\n",
      "training_silo_2 267.60097789764404\n",
      "[17:22:38 INFO] Privacy spent: epsilon = 0.794522032537103 (round 0)\n",
      "aggregation 11.992104053497314\n",
      "[17:22:38 INFO] |----- Global test result of round 0\n",
      "[17:22:38 INFO] \t |----- Test/Acc: 0.52 (100), Test/Loss: nan\n",
      "global_test 0.00168609619140625\n",
      "total 1.6927719116210938e-05\n",
      "[17:22:38 INFO] Finish federated learning simulation\n"
     ]
    }
   ],
   "source": [
    "for _nodes_per_layer in [4, 8, 15]:\n",
    "    run_secure_simulation(seed, n_users, n_silos, n_samples, n_features, n_classes, n_layers, _nodes_per_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter_size 16\n",
      "n_users 10\n",
      "n_silos 5\n",
      "n_samples 10000\n",
      "[16:35:36 INFO] Start federated learning simulation with secure weighting.\n",
      "key_exchange 2.9396181106567383\n",
      "multiplicative_blind_user_hist 4.531608819961548\n",
      "training_silo_0 91.01992702484131\n",
      "training_silo_1 94.6601710319519\n",
      "training_silo_2 88.53735017776489\n",
      "training_silo_3 94.27006006240845\n",
      "training_silo_4 91.61543083190918\n",
      "[16:43:26 INFO] Privacy spent: epsilon = 0.794522032537103 (round 0)\n",
      "aggregation 2.1841750144958496\n",
      "[16:43:26 INFO] |----- Global test result of round 0\n",
      "[16:43:26 INFO] \t |----- Test/Acc: 0.5 (100), Test/Loss: nan\n",
      "global_test 0.00179290771484375\n",
      "total 3.504753112792969e-05\n",
      "[16:43:26 INFO] Finish federated learning simulation\n",
      "parameter_size 16\n",
      "n_users 10\n",
      "n_silos 7\n",
      "n_samples 10000\n",
      "[16:43:38 INFO] Start federated learning simulation with secure weighting.\n",
      "key_exchange 5.725150108337402\n",
      "multiplicative_blind_user_hist 4.887310028076172\n",
      "training_silo_0 83.21179986000061\n",
      "training_silo_1 92.95768213272095\n",
      "training_silo_2 87.23076605796814\n",
      "training_silo_3 96.2587890625\n",
      "training_silo_4 93.93128395080566\n",
      "training_silo_5 84.52289700508118\n",
      "training_silo_6 89.68692398071289\n",
      "[16:54:18 INFO] Privacy spent: epsilon = 0.794522032537103 (round 0)\n",
      "aggregation 2.1623528003692627\n",
      "[16:54:18 INFO] |----- Global test result of round 0\n",
      "[16:54:18 INFO] \t |----- Test/Acc: 0.49 (100), Test/Loss: nan\n",
      "global_test 0.0015952587127685547\n",
      "total 4.57763671875e-05\n",
      "[16:54:18 INFO] Finish federated learning simulation\n",
      "parameter_size 16\n",
      "n_users 10\n",
      "n_silos 9\n",
      "n_samples 10000\n",
      "[16:54:20 INFO] Start federated learning simulation with secure weighting.\n",
      "key_exchange 9.477273941040039\n",
      "multiplicative_blind_user_hist 5.087700128555298\n",
      "training_silo_0 94.12726998329163\n",
      "training_silo_1 79.14221906661987\n",
      "training_silo_2 86.59900283813477\n",
      "training_silo_3 86.83643698692322\n",
      "training_silo_4 78.3361611366272\n",
      "training_silo_5 86.65233302116394\n",
      "training_silo_6 85.84408116340637\n",
      "training_silo_7 82.54178977012634\n",
      "training_silo_8 86.9701840877533\n",
      "[17:07:24 INFO] Privacy spent: epsilon = 0.794522032537103 (round 0)\n",
      "aggregation 2.177841901779175\n",
      "[17:07:24 INFO] |----- Global test result of round 0\n",
      "[17:07:24 INFO] \t |----- Test/Acc: 0.49 (100), Test/Loss: nan\n",
      "global_test 0.0018470287322998047\n",
      "total 1.7881393432617188e-05\n",
      "[17:07:24 INFO] Finish federated learning simulation\n"
     ]
    }
   ],
   "source": [
    "for _n_silos in [5, 7, 9]:\n",
    "    run_secure_simulation(seed, n_users, _n_silos, n_samples, n_features, n_classes, n_layers, nodes_per_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter_size 16\n",
      "n_users 20\n",
      "n_silos 3\n",
      "n_samples 10000\n",
      "[17:22:41 INFO] Start federated learning simulation with secure weighting.\n",
      "key_exchange 1.0518741607666016\n",
      "multiplicative_blind_user_hist 8.142098903656006\n",
      "training_silo_0 179.95025610923767\n",
      "training_silo_1 179.33229804039001\n",
      "training_silo_2 169.8616497516632\n",
      "[17:31:41 INFO] Privacy spent: epsilon = 0.794522032537103 (round 0)\n",
      "aggregation 2.156702995300293\n",
      "[17:31:41 INFO] |----- Global test result of round 0\n",
      "[17:31:41 INFO] \t |----- Test/Acc: 0.5 (100), Test/Loss: 1.1250611543655396\n",
      "global_test 0.0017132759094238281\n",
      "total 1.5735626220703125e-05\n",
      "[17:31:41 INFO] Finish federated learning simulation\n",
      "parameter_size 16\n",
      "n_users 30\n",
      "n_silos 3\n",
      "n_samples 10000\n",
      "[17:31:44 INFO] Start federated learning simulation with secure weighting.\n",
      "key_exchange 1.052083969116211\n",
      "multiplicative_blind_user_hist 12.47703504562378\n",
      "training_silo_0 220.05000114440918\n",
      "training_silo_1 256.8751108646393\n",
      "training_silo_2 241.8202509880066\n",
      "[17:43:58 INFO] Privacy spent: epsilon = 0.794522032537103 (round 0)\n",
      "aggregation 2.148691177368164\n",
      "[17:43:58 INFO] |----- Global test result of round 0\n",
      "[17:43:58 INFO] \t |----- Test/Acc: 0.5 (100), Test/Loss: 0.7105917930603027\n",
      "global_test 0.0017788410186767578\n",
      "total 1.7881393432617188e-05\n",
      "[17:43:58 INFO] Finish federated learning simulation\n",
      "parameter_size 16\n",
      "n_users 40\n",
      "n_silos 3\n",
      "n_samples 10000\n",
      "[17:44:03 INFO] Start federated learning simulation with secure weighting.\n",
      "key_exchange 1.0446362495422363\n",
      "multiplicative_blind_user_hist 16.489341974258423\n",
      "training_silo_0 319.25748205184937\n",
      "training_silo_1 309.42834091186523\n",
      "training_silo_2 336.7686347961426\n",
      "[18:00:28 INFO] Privacy spent: epsilon = 0.794522032537103 (round 0)\n",
      "aggregation 2.1438820362091064\n",
      "[18:00:28 INFO] |----- Global test result of round 0\n",
      "[18:00:28 INFO] \t |----- Test/Acc: 0.15 (100), Test/Loss: 0.8032515645027161\n",
      "global_test 0.002195119857788086\n",
      "total 1.6927719116210938e-05\n",
      "[18:00:28 INFO] Finish federated learning simulation\n"
     ]
    }
   ],
   "source": [
    "for _n_users in [20, 30, 40]:\n",
    "    run_secure_simulation(seed, _n_users, n_silos, n_samples, n_features, n_classes, n_layers, nodes_per_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPC evaluation\n",
    "\n",
    "macOS Monterey Version 12.1\n",
    "MacBook Pro (14-inch, 2021)\n",
    "Chip Apple M1 Max\n",
    "Memory 64GB\n",
    "\n",
    "parameter_size 16\n",
    "n_users 10\n",
    "n_silos 3\n",
    "n_samples 10000\n",
    "le 10\n",
    "\n",
    "key_exchange 1.0501000881195068\n",
    "multiplicative_blind_user_hist 4.100116968154907\n",
    "training_silo 85.51134705543518 94.669105052948 71.39624691009521\n",
    "aggregation 2.1742188930511475\n",
    "\n",
    "# n_samples\n",
    "\n",
    "#### n_samples 10000\n",
    "key_exchange 1.0501000881195068\n",
    "multiplicative_blind_user_hist 4.100116968154907\n",
    "training_silo 85.51134705543518 94.669105052948 71.39624691009521\n",
    "aggregation 2.1742188930511475\n",
    "\n",
    "#### n_samples 1000\n",
    "key_exchange 1.0447149276733398\n",
    "multiplicative_blind_user_hist 4.114915132522583\n",
    "training_silo 86.59528112411499 83.68200397491455 86.97076797485352\n",
    "aggregation 2.145372152328491\n",
    "\n",
    "#### n_samples 100\n",
    "key_exchange 1.051577091217041\n",
    "multiplicative_blind_user_hist 4.12992000579834\n",
    "training_silo 85.44185900688171 84.4896731376648 89.13435697555542\n",
    "aggregation 2.1517958641052246\n",
    "\n",
    "\n",
    "# parameter size\n",
    "\n",
    "\n",
    "#### parameter_size 30\n",
    "key_exchange 1.054563045501709\n",
    "multiplicative_blind_user_hist 4.218053817749023\n",
    "training_silo_0 122.73623919487 94.80184197425842 107.45446586608887\n",
    "aggregation 3.6276512145996094\n",
    "\n",
    "#### parameter_size 58\n",
    "key_exchange 1.044889211654663\n",
    "multiplicative_blind_user_hist 4.1281819343566895\n",
    "training_silo_0 186.789489030838 185.6517848968506 172.2580258846283\n",
    "aggregation 6.741549015045166\n",
    "\n",
    "#### parameter_size 107\n",
    "key_exchange 1.0656218528747559\n",
    "multiplicative_blind_user_hist 4.129354000091553\n",
    "training_silo_0 287.4782841205597\n",
    "training_silo_1 303.5857400894165\n",
    "training_silo_2 267.60097789764404\n",
    "aggregation 11.992104053497314\n",
    "\n",
    "\n",
    "# n_silos\n",
    "\n",
    "#### n_silos 5\n",
    "key_exchange 2.9396181106567383\n",
    "multiplicative_blind_user_hist 4.531608819961548\n",
    "training_silo_0 91.01992702484131\n",
    "training_silo_1 94.6601710319519\n",
    "training_silo_2 88.53735017776489\n",
    "training_silo_3 94.27006006240845\n",
    "training_silo_4 91.61543083190918\n",
    "aggregation 2.1841750144958496\n",
    "\n",
    "#### n_silos 7\n",
    "key_exchange 5.725150108337402\n",
    "multiplicative_blind_user_hist 4.887310028076172\n",
    "training_silo_0 83.21179986000061\n",
    "training_silo_1 92.95768213272095\n",
    "training_silo_2 87.23076605796814\n",
    "training_silo_3 96.2587890625\n",
    "training_silo_4 93.93128395080566\n",
    "training_silo_5 84.52289700508118\n",
    "training_silo_6 89.68692398071289\n",
    "aggregation 2.1623528003692627\n",
    "\n",
    "#### n_silos 9\n",
    "key_exchange 9.477273941040039\n",
    "multiplicative_blind_user_hist 5.087700128555298\n",
    "training_silo_0 94.12726998329163\n",
    "training_silo_1 79.14221906661987\n",
    "training_silo_2 86.59900283813477\n",
    "training_silo_3 86.83643698692322\n",
    "training_silo_4 78.3361611366272\n",
    "training_silo_5 86.65233302116394\n",
    "training_silo_6 85.84408116340637\n",
    "training_silo_7 82.54178977012634\n",
    "training_silo_8 86.9701840877533\n",
    "aggregation 2.177841901779175\n",
    "\n",
    "\n",
    "\n",
    "## n_users\n",
    "\n",
    "#### n_users 20\n",
    "key_exchange 1.0518741607666016\n",
    "multiplicative_blind_user_hist 8.142098903656006\n",
    "training_silo_0 179.95025610923767\n",
    "training_silo_1 179.33229804039001\n",
    "training_silo_2 169.8616497516632\n",
    "aggregation 2.156702995300293\n",
    "\n",
    "\n",
    "#### n_users 30\n",
    "key_exchange 1.052083969116211\n",
    "multiplicative_blind_user_hist 12.47703504562378\n",
    "training_silo_0 220.05000114440918\n",
    "training_silo_1 256.8751108646393\n",
    "training_silo_2 241.8202509880066\n",
    "aggregation 2.148691177368164\n",
    "\n",
    "#### n_users 40\n",
    "key_exchange 1.0446362495422363\n",
    "multiplicative_blind_user_hist 16.489341974258423\n",
    "training_silo_0 319.25748205184937\n",
    "training_silo_1 309.42834091186523\n",
    "training_silo_2 336.7686347961426\n",
    "aggregation 2.1438820362091064"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acsilo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
